
# Configuration version (required)
version: 1.2.1

# Cache settings: Set to true to enable caching
cache: true

# Custom interface configuration
interface:
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true
  speechTab: true

speech:
  speechTab:
    conversationMode: true
    advancedMode: false
    speechToText:
      engineSTT: "external"
      languageSTT: "English (US)"
      autoTranscribeAudio: true
      decibelValue: -45
      autoSendText: 0
    textToSpeech:
      engineTTS: "external"
      voice: "alloy"
      languageTTS: "en"
      automaticPlayback: true
      playbackRate: 1.0
      cacheTTS: true
  tts:
    openai:
      apiKey: '${TTS_API_KEY}'
      model: 'tts-1'
      voices: ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer'] 
  stt:
    openai:
      apiKey: '${STT_API_KEY}'
      model: 'whisper-1'

endpoints:
  agents:
    recursionLimit: 50
    disableBuilder: false
    # (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.
    # capabilities: ["execute_code", "file_search", "actions", "tools"]
  custom:
    # APIpie
    # https://apipie.ai/dashboard/
    # Script to fetch models: https://github.com/LibreChat-AI/librechat-config-yaml/blob/main/scripts/apipie.py
    - name: "APIpie"
      apiKey: "${APIPIE_API_KEY}"
      baseURL: "https://apipie.ai/v1/"
      models:
        default: [
          "DeepSeek-V3",
          "Llama-2-13b-chat-hf",
          "Llama-2-70b-chat-hf",
          "Llama-2-70b-hf",
          "Llama-2-7b-chat-hf",
          "Llama-3-70b-chat-hf",
          "Llama-3-8b-chat-hf",
          "Llama-3.1-Nemotron-70B-Instruct-HF",
          "Llama-3.2-11B-Vision-Instruct-Turbo",
          "Llama-3.2-3B-Instruct-Turbo",
          "Llama-3.2-90B-Vision-Instruct-Turbo",
          "Llama-3.3-70B-Instruct-Turbo",
          "Llama-Rank-V1",
          "Meta-Llama-3-70B-Instruct",
          "Meta-Llama-3-70B-Instruct-Lite",
          "Meta-Llama-3-70B-Instruct-Turbo",
          "Meta-Llama-3-8B-Instruct",
          "Meta-Llama-3-8B-Instruct-Lite",
          "Meta-Llama-3-8B-Instruct-Turbo",
          "Meta-Llama-3.1-405B-Instruct-Turbo",
          "Meta-Llama-3.1-70B-Instruct-Turbo",
          "Meta-Llama-3.1-8B-Instruct-Turbo",
          "Meta-Llama-3.1-8B-Instruct-Turbo-128K",
          "Mistral-7B-Instruct-v0.1",
          "Mistral-7B-Instruct-v0.2",
          "Mistral-7B-Instruct-v0.3",
          "Mistral-7B-v0.1",
          "Mixtral-8x22B-Instruct-v0.1",
          "Mixtral-8x22B-v0.1",
          "Mixtral-8x7B-Instruct-v0.1",
          "Mixtral-8x7B-v0.1",
          "MythoMax-L2-13b",
          "MythoMax-L2-13b-Lite",
          "Nous-Hermes-2-Mixtral-8x7B-DPO",
          "QwQ-32B-Preview",
          "Qwen2-72B-Instruct",
          "Qwen2-VL-72B-Instruct",
          "Qwen2.5-72B-Instruct-Turbo",
          "Qwen2.5-7B-Instruct-Turbo",
          "SOLAR-10.7B-Instruct-v1.0",
          "WizardLM-2-7B",
          "WizardLM-2-8x22B",
          "airoboros-70b",
          "airoboros-l2-70b",
          "anthropic.claude-3-5-sonnet-20240620-v1:0",
          "chatgpt-4o-latest",
          "chatx_cheap_128k",
          "chatx_cheap_32k",
          "chatx_cheap_4k",
          "chatx_cheap_64k",
          "chatx_cheap_8k",
          "chatx_mids_4k",
          "chatx_premium_128k",
          "chatx_premium_32k",
          "chatx_premium_4k",
          "chatx_premium_8k",
          "chronos-hermes-13b-v2",
          "command",
          "command-light",
          "command-light-nightly",
          "command-light-text-v14",
          "command-nightly",
          "command-r",
          "command-r-03-2024",
          "command-r-08-2024",
          "command-r-plus",
          "command-r-plus-04-2024",
          "command-r-plus-08-2024",
          "command-r-plus-v1",
          "command-r-v1",
          "command-r7b-12-2024",
          "command-text-v14",
          "dbrx-instruct",
          "deepseek-chat",
          "deepseek-chat-v2.5",
          "deepseek-llm-67b-chat",
          "dolphin-2.6-mixtral-8x7b",
          "dolphin-mixtral-8x22b",
          "dolphin-mixtral-8x7b",
          "eva-llama-3.33-70b",
          "eva-qwen-2.5-32b",
          "eva-qwen-2.5-72b",
          "gemma-1.1-7b-it",
          "gemma-2-27b-it",
          "gemma-2-9b-it",
          "gemma-2b-it",
          "gemma-7b-it",
          "general",
          "goliath-120b",
          "grok-2-1212",
          "grok-2-vision-1212",
          "grok-beta",
          "grok-vision-beta",
          "hermes-2-pro-llama-3-8b",
          "hermes-3-llama-3.1-405b",
          "hermes-3-llama-3.1-70b",
          "inflection-3-pi",
          "j2-grande-instruct",
          "j2-jumbo-instruct",
          "j2-mid",
          "j2-mid-v1",
          "j2-ultra",
          "j2-ultra-v1",
          "jamba-1-5-large",
          "jamba-1-5-large-v1",
          "jamba-1-5-mini",
          "jamba-1-5-mini-v1",
          "jamba-instruct",
          "jamba-instruct-v1",
          "l3-euryale-70b",
          "l3-lunaris-8b",
          "l3.1-70b-hanami-x1",
          "l3.1-euryale-70b",
          "l3.3-euryale-70b",
          "large-latest",
          "lfm-40b",
          "llama-2-13b-chat",
          "llama-3-70b-instruct",
          "llama-3-8b-instruct",
          "llama-3-lumimaid-70b",
          "llama-3-lumimaid-8b",
          "llama-3-sonar-large-32k-chat",
          "llama-3.1-405b",
          "llama-3.1-405b-instruct",
          "llama-3.1-70b-instruct",
          "llama-3.1-8b-instruct",
          "llama-3.1-lumimaid-70b",
          "llama-3.1-lumimaid-8b",
          "llama-3.1-nemotron-70b-instruct",
          "llama-3.1-sonar-huge-128k-online",
          "llama-3.1-sonar-large-128k-chat",
          "llama-3.1-sonar-large-128k-online",
          "llama-3.1-sonar-small-128k-chat",
          "llama-3.1-sonar-small-128k-online",
          "llama-3.2-11b-vision-instruct",
          "llama-3.2-1b-instruct",
          "llama-3.2-3b-instruct",
          "llama-3.2-90b-vision-instruct",
          "llama-3.3-70b-instruct",
          "llama-4-scout",
          "llama-4-maverick",
          "llama-guard-2-8b",
          "llama2-13b-chat-v1",
          "llama2-70b-chat-v1",
          "llama3-1",
          "llama3-1-405b-instruct-v1:0",
          "llama3-1-70b-instruct-v1",
          "llama3-1-70b-instruct-v1:0",
          "llama3-1-8b-instruct-v1",
          "llama3-1-8b-instruct-v1:0",
          "llama3-2",
          "llama3-2-11b-instruct-v1",
          "llama3-2-1b-instruct-v1",
          "llama3-2-3b-instruct-v1",
          "llama3-2-90b-instruct-v1",
          "llama3-3-70b-instruct-v1",
          "llama3-70b-instruct-v1",
          "llama3-70b-instruct-v1:0",
          "llama3-8b-instruct-v1",
          "llama3-8b-instruct-v1:0",
          "magnum-72b",
          "magnum-v2-72b",
          "magnum-v4-72b",
          "medium",
          "meta-llama-3.1-8b-instruct",
          "midnight-rose-70b",
          "ministral-3b",
          "ministral-3b-latest",
          "ministral-8b",
          "ministral-8b-latest",
          "mistral",
          "mistral-7b-instruct",
          "mistral-7b-instruct-v0",
          "mistral-7b-instruct-v0.1",
          "mistral-7b-instruct-v0.3",
          "mistral-large",
          "mistral-large-2402-v1",
          "mistral-large-2407",
          "mistral-large-2411",
          "mistral-large-latest",
          "mistral-medium",
          "mistral-nemo",
          "mistral-small",
          "mistral-small-2402-v1",
          "mistral-small-latest",
          "mistral-tiny",
          "mixtral",
          "mixtral-8x22b-instruct",
          "mixtral-8x7b",
          "mixtral-8x7b-instruct",
          "mixtral-8x7b-instruct-v0",
          "mn-celeste-12b",
          "mn-inferor-12b",
          "mn-starcannon-12b",
          "mythalion-13b",
          "mythomax-l2-13b",
          "nai-meta-v1",
          "noromaid-20b",
          "nous-hermes-2-mixtral-8x7b-dpo",
          "nous-hermes-2-vision-7b",
          "nous-hermes-llama2-13b",
          "nova-canvas-v1",
          "nova-lite-v1",
          "nova-micro-v1",
          "nova-pro-v1",
          "nova-reel-v1",
          "olympus-premier-v1",
          "online-llama",
          "openchat-7b",
          "openchat_3.5",
          "openhermes-2.5-mistral-7b",
          "palm-2-chat-bison",
          "palm-2-chat-bison-32k",
          "phi-3-medium-128k-instruct",
          "phi-3-mini-128k-instruct",
          "phi-3.5-mini-128k-instruct",
          "phi-4",
          "pixtral-12b",
          "pixtral-large-2411",
          "qvq-72b-preview",
          "qwen-2-72b-instruct",
          "qwen-2-7b-instruct",
          "qwen-2-vl-72b-instruct",
          "qwen-2-vl-7b-instruct",
          "qwen-2.5-72b-instruct",
          "qwen-2.5-7b-instruct",
          "qwen1-5",
          "qwen2",
          "qwq-32b-preview",
          "remm-slerp-l2-13b",
          "rocinante-12b",
          "scb10x-llama3-typhoon-v1-5-8b-instruct",
          "scb10x-llama3-typhoon-v1-5x-4f316",
          "small",
          "sorcererlm-8x22b",
          "tiny",
          "titan",
          "titan-text-express-v1",
          "titan-text-lite-v1",
          "titan-text-premier-v1",
          "titan-tg1-large",
          "toppy-m-7b",
          "unslopnemo-12b",
          "weaver",
          "wizardlm-2-7b",
          "wizardlm-2-8x22b",
          "xwin-lm-70b",
          "yi-large",
          "yi-vision",
          "zephyr-orpo-141b-A35b-v0.1"
          ]
        fetch: false
      titleConvo: true
      titleModel: "claude-3-haiku"
      summarize: false
      summaryModel: "claude-3-haiku"
      dropParams: ["stream"]
      modelDisplayLabel: "APIpie"
      iconURL: "https://raw.githubusercontent.com/webpug/PugChat/main/icons/aetherIcon1.png"

    # deepseek
    # https://platform.deepseek.com/api_keys
    # Model list: https://platform.deepseek.com/api-docs/pricing
    - name: "deepseek"
      apiKey: "${DEEPSEEK_API_KEY}"
      baseURL: "https://api.deepseek.com"
      models:
        default: [
          "deepseek-chat",
          "deepseek-coder",
          "deepseek-reasoner",
          ]
        fetch: false
      titleConvo: true
      titleModel: "deepseek-chat"
      summarize: false
      summaryModel: "deepseek-chat"
      modelDisplayLabel: "DeepSeek"

    # HuggingFace
    # https://huggingface.co/settings/tokens
    - name: 'HuggingFace'
      apiKey: '${HUGGINGFACE_TOKEN}'
      baseURL: 'https://api-inference.huggingface.co/v1'
      models:
        default: [
          "codellama/CodeLlama-34b-Instruct-hf",
          "google/gemma-1.1-2b-it",
          "google/gemma-1.1-7b-it",
          "HuggingFaceH4/starchat2-15b-v0.1",
          "HuggingFaceH4/zephyr-7b-beta",
          "meta-llama/Meta-Llama-3-8B-Instruct",
          "meta-llama/Llama-4-Scout-17B-16E-Instruct",
          "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
          "microsoft/Phi-3-mini-4k-instruct",
          "mistralai/Mistral-7B-Instruct-v0.1",
          "mistralai/Mistral-7B-Instruct-v0.2",
          "mistralai/Mixtral-8x7B-Instruct-v0.1",
          "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
          ]
        fetch: true
      titleConvo: true
      titleModel: "microsoft/Phi-3-mini-4k-instruct"
      # parameters: 
      #   defaults:
      #     temperature: 0.9
      #     max_new_tokens: 512
      dropParams: ["top_p"]
      modelDisplayLabel: "HuggingFace"

    # Preplexity
    # Model list: https://docs.perplexity.ai/docs/model-cards
    - name: "Perplexity"
      apiKey: "${PERPLEXITY_API_KEY}"
      baseURL: "https://api.perplexity.ai/"
      models:
        default: [
          "sonar-reasoning-pro",
          "sonar-reasoning",
          "sonar-pro",
          "sonar"
          ]
        fetch: false # fetching list of models is not supported
      titleConvo: true
      titleModel: "sonar-pro"
      summarize: false
      summaryModel: "sonar-pro"
      forcePrompt: false
      dropParams: ["stop", "frequency_penalty"]
      modelDisplayLabel: "Perplexity"
    - name: "Grok"
      apiKey: "${GROK_API_KEY}"
      baseURL: "https://api.x.ai/v1"
      models:
        default: [
          "grok-3-latest",
          "grok-3-mini-beta",
          "grok-3-fast-beta",
          "grok-2-1212",
          "grok-2-vision-1212",
          "grok-2-image-1212",
          "grok-beta",
          "grok-vision-beta"
        ]
        fetch: false
      titleConvo: true
      titleModel: "grok-3-latest"
      summarize: false
      summaryModel: "grok-3-latest"
      modelDisplayLabel: "Grok"
      iconURL: "https://raw.githubusercontent.com/webpug/PugChat/main/icons/xAIlogo.png"

